# ğŸ§  NLP-Projekt: Klassifizierung von Katastrophen-Tweets

Dieses Projekt untersucht, wie gut sich Tweets automatisch in **â€Katastropheâ€œ (1)** oder **â€Keine Katastropheâ€œ (0)** einordnen lassen.  
Der Fokus liegt auf natÃ¼rlicher Sprachverarbeitung (NLP), Textbereinigung, Feature-Engineering und Modellvergleich im Machine Learning.

---

## ğŸ“ ProjektÃ¼bersicht

Das Ziel:  
Ein ML-Modell entwickeln, das echten Katastrophen-Tweets erkennt und von nicht-kritischen Tweets unterscheidet.

DafÃ¼r habe ich:

- den Datensatz bereinigt (NLP Preprocessing)
- die Texte mit **TFâ€“IDF** in numerische Features umgewandelt
- drei Modelle trainiert und verglichen  
- das beste Modell ausgewÃ¤hlt (Logistische Regression)
- Cross-Validation und Hyperparameter-Tuning durchgefÃ¼hrt
- alle Ergebnisse dokumentiert und interpretiert

---

## ğŸ“Š Datensatz

**train.csv**  
- **text** â†’ Tweet  
- **target** â†’ 1 = Katastrophe, 0 = keine Katastrophe  
- 7.613 Zeilen, keine fehlenden Werte  

Der Datensatz stammt aus der Kaggle-Competition  
**â€œReal or Not? Disaster Tweetsâ€**.

---

## ğŸ”§ Verwendete Techniken

### ğŸ§¹ 1. Text Preprocessing
- Lowercasing  
- Entfernen von Sonderzeichen  
- Tokenisierung  
- Entfernen englischer Stopwords  
- Lemmatisierung (WordNet)  

### ğŸ”  2. Feature Engineering
- **TFâ€“IDF Vectorizer**  
- Begrenzung auf 5.000 Features  
- Sparse-Matrix-Darstellung  

### ğŸ¤– 3. Modelle
Trainiert & verglichen wurden:

| Modell | Accuracy | StÃ¤rken |
|-------|----------|---------|
| **Logistische Regression** | **81.88 %** | Sehr balanciert, stabil, ideal fÃ¼r Text |
| **Random Forest** | 80.43 % | Gute SensitivitÃ¤t, aber weniger prÃ¤zise |
| **MLP Neuronales Netz** | 81.68 % | Starke Ergebnisse, robust gegen Rauschen |

---

## ğŸ¥‡ Bestes Modell: Logistische Regression

Die Logistische Regression erzielte die beste Gesamt-Performance:

- **Accuracy:** 81.88 %  
- **Sehr gute Balance** zwischen Precision/Recall  
- Funktioniert besonders gut mit TFâ€“IDF   
- Schnell, interpretierbar und stabil  

### Beispiel aus der Konfusionsmatrix:
- **True Positives (Katastrophe richtig erkannt):** 456  
- **False Negatives (Ã¼bersehene Katastrophen):** 198  
- **True Negatives:** 791  
- **False Positives:** 78  

---

## ğŸ§ª Validierung & Tuning

### âœ”ï¸ 5-fold Cross-Validation  
Ergebnis:  
- Durchschnitts-Accuracy: **70.18 %**  
- Standardabweichung: 3.86 %  

### âœ”ï¸ Hyperparameter Tuning (GridSearchCV)
Getestet wurden:  
- Solver: `liblinear`, `lbfgs`  
- Regularisierung `C = [0.1, 1.0, 10.0]`  

**Bestes Setup:**  
- `solver = lbfgs`  
- `C = 1.0`  
â†’ identische Performance wie Standardparameter, aber bestÃ¤tigt deren StabilitÃ¤t.

---

## ğŸ“ˆ Fazit

In diesem Projekt habe ich einen vollstÃ¤ndigen NLP-Pipeline-Workflow umgesetzt.  
Ich konnte sehen, wie stark **Preprocessing und Vektorisierung** die Modellleistung beeinflussen und wie unterschiedlich ML-Modelle mit Textdaten umgehen.

**Die wichtigsten Erkenntnisse:**

- Gute Textvorbereitung ist der halbe Erfolg.  
- TFâ€“IDF ist fÃ¼r klassische ML-Modelle eine sehr starke Wahl.  
- Die Logistische Regression liefert eine hervorragende Basis.  
- Modelle sollten immer mit Recall & Konfusionsmatrix bewertet werden â€“ nicht nur mit Accuracy.  
- Komplexere Modelle (MLP, Random Forest) bieten spannende Alternativen, je nach Zielsetzung.  

---

## ğŸš€ Ausblick

Wenn ich das Projekt erweitern wÃ¼rde:

- Einsatz moderner Embeddings (*Word2Vec, GloVe*)  
- Training eines BERT-Modells (z. B. `bert-base-uncased`)  
- Ausbau zu einer kleinen API, die Tweets live klassifiziert  
- Experimentieren mit Class-Weights, um Klasse 1 (Katastrophen) noch besser zu erkennen  

---

## ğŸ’» Projekt-Notebook und PrÃ¤sentation

Hier findest du das vollstÃ¤ndige Colab-Notebook mit allen Code-Zellen, Auswertungen und Visualisierungen:

ğŸ‘‰ **[Klick hier, um das Notebook zu Ã¶ffnen](https://colab.research.google.com/drive/1FKv3lVJh5tHWga-jMcdc2srv_f7tQZQi?usp=sharing)**  

Und hier findest du die dazu passende PrÃ¤sentation:

ğŸ‘‰ **[Klick hier, um die PrÃ¤sentation zu Ã¶ffnen](https://www.canva.com/design/DAG5_OdMV_U/pWaS03bKNLiNdcyLEWRe1Q/edit?utm_content=DAG5_OdMV_U&utm_campaign=designshare&utm_medium=link2&utm_source=sharebutton)**  

---

## ğŸ“¬ Kontakt

Wenn du Feedback oder Fragen hast â€” gerne melden!  
Ich freue mich Ã¼ber Austausch zu NLP, Machine Learning und Data Analytics.
